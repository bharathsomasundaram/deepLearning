{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc99f73-1f8d-4f94-a497-7fb5e9652962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb727bad-325e-456a-9105-b6ff02d4b9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d01022d1-bbc0-43fa-ba9e-3579b70dc002",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_low, root_high, transform=None):\n",
    "        self.root_low = root_low\n",
    "        self.root_high = root_high\n",
    "        self.low_images = os.listdir(root_low)\n",
    "        self.high_images = os.listdir(root_high)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.low_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        low_img_name = os.path.join(self.root_low, self.low_images[idx])\n",
    "        high_img_name = os.path.join(self.root_high, self.low_images[idx])  # Assuming same file names in low and high dirs\n",
    "        low_img = Image.open(low_img_name).convert('RGB')\n",
    "        high_img = Image.open(high_img_name).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            low_img = self.transform(low_img)\n",
    "            high_img = self.transform(high_img)\n",
    "\n",
    "        return low_img, high_img\n",
    "\n",
    "# Define transformation for preprocessing\n",
    "transform = ToTensor()\n",
    "\n",
    "# Dataset paths\n",
    "train_low_dir = \"C:/Users/scdes/OneDrive/Desktop/archive/lol_dataset/Train/low/\"\n",
    "train_high_dir = \"C:/Users/scdes/OneDrive/Desktop/archive/lol_dataset/Train/high/\"\n",
    "test_low_dir = \"C:/Users/scdes/OneDrive/Desktop/archive/lol_dataset/Test/low/\"\n",
    "test_high_dir = \"C:/Users/scdes/OneDrive/Desktop/archive/lol_dataset/Test/high/\"\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = CustomDataset(train_low_dir, train_high_dir, transform=transform)\n",
    "test_dataset = CustomDataset(test_low_dir, test_high_dir, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd2ab4d8-020e-4a22-bb1d-d54a8dc8fe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the diffusion model\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder_conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.encoder_conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.encoder_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder_upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.decoder_conv1 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.decoder_conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.decoder_conv3 = nn.Conv2d(64, 3, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = nn.functional.relu(self.encoder_conv1(x))\n",
    "        x2 = nn.functional.relu(self.encoder_conv2(x1))\n",
    "        x_pool = self.encoder_pool(x2)\n",
    "\n",
    "        # Decoder\n",
    "        x_upsample = self.decoder_upsample(x_pool)\n",
    "        x_concat = torch.cat([x2, x_upsample], dim=1)\n",
    "        x3 = nn.functional.relu(self.decoder_conv1(x_concat))\n",
    "        x4 = nn.functional.relu(self.decoder_conv2(x3))\n",
    "        x_out = nn.functional.relu(self.decoder_conv3(x4))\n",
    "        \n",
    "        return x_out\n",
    "\n",
    "# Define PSNR function\n",
    "def psnr(img1, img2):\n",
    "    mse = torch.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * torch.log10(1.0 / torch.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a210396b-f6d7-453b-8223-f7eeec1c8b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the diffusion model and move it to GPU\n",
    "model = DiffusionModel().to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "train_psnr_history = []\n",
    "test_psnr_history = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_psnr_sum = 0.0\n",
    "    train_num_samples = 0\n",
    "    for inputs, targets in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs} - Training'):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = torch.mean((outputs - targets)**2)  # Mean Squared Error loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate PSNR on training data\n",
    "        train_psnr_sum += torch.sum(psnr(outputs, targets))\n",
    "        train_num_samples += inputs.size(0)\n",
    "    avg_train_psnr = train_psnr_sum / train_num_samples\n",
    "    train_psnr_history.append(avg_train_psnr.item())\n",
    "\n",
    "    # Evaluate PSNR on test dataset\n",
    "    model.eval()\n",
    "    test_psnr_sum = 0.0\n",
    "    test_num_samples = 0\n",
    "    for inputs, targets in tqdm(test_loader, desc=f'Epoch {epoch + 1}/{num_epochs} - Testing'):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)  # Move data to GPU\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            for i in range(inputs.size(0)):\n",
    "                test_psnr_sum += psnr(outputs[i], targets[i])\n",
    "                test_num_samples += 1\n",
    "    avg_test_psnr = test_psnr_sum / test_num_samples\n",
    "    test_psnr_history.append(avg_test_psnr.item())\n",
    "    print(f'Average PSNR on test dataset: {avg_test_psnr:.2f} dB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cbf71ae-f57c-4c2f-9d6e-ec9f138c8470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Training: 100%|███████████████████████████████████████████████████████████| 16/16 [12:08<00:00, 45.53s/it]\n",
      "Epoch 1/10 - Testing: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:12<00:00, 12.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR on test dataset: 15.00 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Training:  25%|███████████████                                             | 4/16 [05:08<15:25, 77.09s/it]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 938.00 MiB. GPU 0 has a total capacty of 6.00 GiB of which 0 bytes is free. Of the allocated memory 11.10 GiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast():\n\u001b[1;32m---> 26\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean((outputs \u001b[38;5;241m-\u001b[39m targets)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Mean Squared Error loss\u001b[39;00m\n\u001b[0;32m     28\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\deeplearning\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\deeplearning\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 27\u001b[0m, in \u001b[0;36mDiffusionModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     25\u001b[0m x_concat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x2, x_upsample], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     26\u001b[0m x3 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_conv1(x_concat))\n\u001b[1;32m---> 27\u001b[0m x4 \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder_conv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx3\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m x_out \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_conv3(x4))\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x_out\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\deeplearning\\lib\\site-packages\\torch\\nn\\functional.py:1471\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1469\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1470\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1471\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 938.00 MiB. GPU 0 has a total capacty of 6.00 GiB of which 0 bytes is free. Of the allocated memory 11.10 GiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "# Initialize the scaler for mixed precision training\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Initialize the diffusion model and move it to GPU\n",
    "model = DiffusionModel().to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "train_psnr_history = []\n",
    "test_psnr_history = []\n",
    "\n",
    "# Replace the training loop with this code\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_psnr_sum = 0.0\n",
    "    train_num_samples = 0\n",
    "    for inputs, targets in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs} - Training'):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = torch.mean((outputs - targets)**2)  # Mean Squared Error loss\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Calculate PSNR on training data\n",
    "        train_psnr_sum += torch.sum(psnr(outputs, targets))\n",
    "        train_num_samples += inputs.size(0)\n",
    "    avg_train_psnr = train_psnr_sum / train_num_samples\n",
    "    train_psnr_history.append(avg_train_psnr.item())\n",
    "\n",
    "    # Evaluate PSNR on test dataset\n",
    "    model.eval()\n",
    "    test_psnr_sum = 0.0\n",
    "    test_num_samples = 0\n",
    "    for inputs, targets in tqdm(test_loader, desc=f'Epoch {epoch + 1}/{num_epochs} - Testing'):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)  # Move data to GPU\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            for i in range(inputs.size(0)):\n",
    "                test_psnr_sum += psnr(outputs[i], targets[i])\n",
    "                test_num_samples += 1\n",
    "    avg_test_psnr = test_psnr_sum / test_num_samples\n",
    "    test_psnr_history.append(avg_test_psnr.item())\n",
    "    print(f'Average PSNR on test dataset: {avg_test_psnr:.2f} dB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b6d16a-4c7e-4ce9-9543-2be341a59c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"diffusion_model.pth\")\n",
    "\n",
    "# Plot training and testing PSNR history\n",
    "plt.plot(train_psnr_history, label='Training PSNR')\n",
    "plt.plot(test_psnr_history, label='Testing PSNR')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('PSNR (dB)')\n",
    "plt.title('Training and Testing PSNR')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('psnr_history.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277fd77-811f-45b8-b107-429e7752d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print low, predicted, and high-resolution images for all samples in the test set\n",
    "model.eval()\n",
    "for inputs, targets in test_loader:\n",
    "    inputs, targets = inputs.to(device), targets.to(device)  # Move data to GPU\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        for i in range(inputs.size(0)):\n",
    "            low_img = transforms.ToPILImage()(inputs[i].cpu())\n",
    "            pred_img = transforms.ToPILImage()(outputs[i].cpu())\n",
    "            high_img = transforms.ToPILImage()(targets[i].cpu())\n",
    "            low_img.show(title='Low-Resolution Image')\n",
    "            pred_img.show(title='Predicted Image')\n",
    "            high_img.show(title='High-Resolution Image')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
