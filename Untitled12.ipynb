{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cJFhRTRhTVZQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# Define paths to image folders\n",
        "train_low_folder = \"C:/Users/scdes/OneDrive/Desktop/archive/lol_dataset/Train/low\"  # Path to folder containing low-resolution training images\n",
        "train_high_folder = \"C:/Users/scdes/OneDrive/Desktop/archive/lol_dataset/Train/high\"  # Path to folder containing high-resolution training images\n",
        "eval_low_folder = \"C:/Users/scdes/OneDrive/Desktop/archive/lol_dataset/Test/low\"  # Path to folder containing low-resolution evaluation images\n",
        "eval_high_folder = \"C:/Users/scdes/OneDrive/Desktop/archive/lol_dataset/Test/high\"  # Path to folder containing high-resolution evaluation images\n",
        "\n",
        "# Load low-resolution and high-resolution images using OpenCV\n",
        "train_low_images = [cv2.imread(os.path.join(train_low_folder, filename)) for filename in os.listdir(train_low_folder)]\n",
        "train_high_images = [cv2.imread(os.path.join(train_high_folder, filename)) for filename in os.listdir(train_high_folder)]\n",
        "eval_low_images = [cv2.imread(os.path.join(eval_low_folder, filename)) for filename in os.listdir(eval_low_folder)]\n",
        "eval_high_images = [cv2.imread(os.path.join(eval_high_folder, filename)) for filename in os.listdir(eval_high_folder)]\n",
        "\n",
        "# Check if GPU is available and set device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Uh8pCOF8TZ1j"
      },
      "outputs": [],
      "source": [
        "# Define the dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, low_res_images, high_res_images, transform=None):\n",
        "        self.low_res_images = low_res_images\n",
        "        self.high_res_images = high_res_images\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.low_res_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        low_res_image = self.low_res_images[idx]\n",
        "        high_res_image = self.high_res_images[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            low_res_image = self.transform(low_res_image)\n",
        "            high_res_image = self.transform(high_res_image)\n",
        "\n",
        "        return low_res_image.to(device), high_res_image.to(device)\n",
        "\n",
        "# Define data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize images\n",
        "])\n",
        "\n",
        "# Create custom datasets\n",
        "train_dataset = CustomDataset(train_low_images, train_high_images, transform=transform)\n",
        "eval_dataset = CustomDataset(eval_low_images, eval_high_images, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "eval_loader = DataLoader(eval_dataset, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jbNAeol3TgEe"
      },
      "outputs": [],
      "source": [
        "# Define the model architecture\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.batchnorm = nn.BatchNorm2d(channels)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.batchnorm(x)\n",
        "        x += residual\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "class DiffusionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DiffusionModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.residual_blocks = nn.ModuleList([ResidualBlock(64) for _ in range(8)])\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 3, kernel_size=3, padding=1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.activation(x)\n",
        "        for block in self.residual_blocks:\n",
        "            x = block(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lNNUZCaLTPwX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Training Loss: 0.16694472879555422\n",
            "Epoch 2, Training Loss: 0.16026146386164367\n",
            "Epoch 3, Training Loss: 0.1586519350364958\n",
            "Epoch 4, Training Loss: 0.15794278440478537\n",
            "Epoch 5, Training Loss: 0.15625109654880062\n",
            "Epoch 6, Training Loss: 0.15586176884466224\n",
            "Epoch 7, Training Loss: 0.1548072091198152\n",
            "Epoch 8, Training Loss: 0.15365665394851227\n",
            "Epoch 9, Training Loss: 0.15312550265879668\n",
            "Epoch 10, Training Loss: 0.15289105550798865\n",
            "Epoch 11, Training Loss: 0.15281893204052732\n",
            "Epoch 12, Training Loss: 0.15223993650762382\n",
            "Epoch 13, Training Loss: 0.15241134468581258\n",
            "Epoch 14, Training Loss: 0.1517606733578075\n",
            "Epoch 15, Training Loss: 0.1520092365015106\n",
            "Epoch 16, Training Loss: 0.15077993794507588\n",
            "Epoch 17, Training Loss: 0.15091620184020282\n",
            "Epoch 18, Training Loss: 0.15067109908985415\n",
            "Epoch 19, Training Loss: 0.1504421970739807\n",
            "Epoch 20, Training Loss: 0.14995513027437876\n",
            "Epoch 21, Training Loss: 0.15029869561573278\n",
            "Epoch 22, Training Loss: 0.14992297512776764\n",
            "Epoch 23, Training Loss: 0.14927805827104862\n",
            "Epoch 24, Training Loss: 0.1490076132195512\n",
            "Epoch 25, Training Loss: 0.14926773239618418\n",
            "Epoch 26, Training Loss: 0.14895433199582334\n",
            "Epoch 27, Training Loss: 0.14877411895191547\n",
            "Epoch 28, Training Loss: 0.14806465985848732\n",
            "Epoch 29, Training Loss: 0.14813965529817896\n",
            "Epoch 30, Training Loss: 0.14752395947646235\n",
            "Epoch 31, Training Loss: 0.1479395948254417\n",
            "Epoch 32, Training Loss: 0.14775299836603023\n",
            "Epoch 33, Training Loss: 0.14761096733555043\n",
            "Epoch 34, Training Loss: 0.14723178423633895\n",
            "Epoch 35, Training Loss: 0.1469053320394656\n",
            "Epoch 36, Training Loss: 0.14683655158991052\n",
            "Epoch 37, Training Loss: 0.14630447300439028\n",
            "Epoch 38, Training Loss: 0.14622847394076818\n",
            "Epoch 39, Training Loss: 0.14624188996313772\n",
            "Epoch 40, Training Loss: 0.1461003594484526\n",
            "Epoch 41, Training Loss: 0.14608413385822602\n",
            "Epoch 42, Training Loss: 0.1454335358281879\n",
            "Epoch 43, Training Loss: 0.14570698914761396\n",
            "Epoch 44, Training Loss: 0.1448587220776634\n",
            "Epoch 45, Training Loss: 0.14493223652627665\n",
            "Epoch 46, Training Loss: 0.1446939554871972\n"
          ]
        }
      ],
      "source": [
        "# Initialize the model and move it to the device\n",
        "model = DiffusionModel().to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, targets in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "    print(f\"Epoch {epoch+1}, Training Loss: {running_loss / len(train_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zw0akfk2TqaQ"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "model.eval()\n",
        "eval_loss = 0.0\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in eval_loader:\n",
        "        outputs = model(inputs)\n",
        "        eval"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
